#loc = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0)
#loc1 = loc(unknown)
#loc19 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":484:44)
#loc24 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":209:116)
#loc26 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":155:42)
#loc37 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":160:21)
#loc52 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":210:116)
#loc78 = loc(callsite(#loc24 at #loc19))
#loc79 = loc(callsite(#loc52 at #loc19))
#loc83 = loc(callsite(#loc26 at #loc78))
#loc92 = loc(callsite(#loc37 at #loc78))
#loc107 = loc(callsite(#loc26 at #loc79))
#loc116 = loc(callsite(#loc37 at #loc79))
#loc131 = loc(callsite(#loc1 at #loc83))
#loc133 = loc(callsite(#loc1 at #loc92))
#loc135 = loc(callsite(#loc1 at #loc107))
#loc137 = loc(callsite(#loc1 at #loc116))
module {
  tt.func public @_attn_fwd_tma_dp(%arg0: f32 loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32} loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg2: i32 loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg3: i32 {tt.divisibility = 16 : i32} loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg4: !tt.tensordesc<tensor<128x128xf16>> loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg5: i32 loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg6: i32 loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg7: i64 loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg8: i64 loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg9: !tt.tensordesc<tensor<128x128xf16>> loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg10: i32 loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg11: i32 loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg12: i64 loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg13: i64 loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg14: !tt.tensordesc<tensor<128x128xf16>> loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg15: i32 loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg16: i32 loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg17: i64 loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg18: i64 loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg19: !tt.tensordesc<tensor<128x128xf16>> loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg20: i32 loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg21: i32 loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg22: i64 loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg23: i64 loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0), %arg24: i32 {tt.divisibility = 16 : i32} loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":441:0)) attributes {noinline = false} {
    %cst = arith.constant dense<1.000000e+00> : tensor<128xf32> loc(#loc1)
    %cst_0 = arith.constant dense<0xFF800000> : tensor<128xf32> loc(#loc1)
    %cst_1 = arith.constant dense<0.000000e+00> : tensor<128x128xf32> loc(#loc1)
    %c128_i32 = arith.constant 128 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %cst_2 = arith.constant 1.44269502 : f32 loc(#loc1)
    %c256_i32 = arith.constant 256 : i32 loc(#loc1)
    %0 = tt.get_program_id x : i32 loc(#loc2)
    %1 = tt.get_program_id y : i32 loc(#loc3)
    %2 = arith.divsi %1, %arg3 : i32 loc(#loc4)
    %3 = arith.remsi %1, %arg3 : i32 loc(#loc5)
    %4 = arith.muli %3, %arg24 : i32 loc(#loc6)
    %5 = arith.addi %2, %4 : i32 loc(#loc7)
    %6 = arith.muli %0, %c256_i32 : i32 loc(#loc8)
    %7 = arith.addi %5, %6 : i32 loc(#loc9)
    %8 = tt.make_range {end = 128 : i32, start = 0 : i32} : tensor<128xi32> loc(#loc10)
    %9 = tt.splat %6 : i32 -> tensor<128xi32> loc(#loc11)
    %10 = arith.addi %9, %8 : tensor<128xi32> loc(#loc11)
    %11 = tt.make_range {end = 256 : i32, start = 128 : i32} : tensor<128xi32> loc(#loc12)
    %12 = arith.addi %9, %11 : tensor<128xi32> loc(#loc13)
    %13 = arith.mulf %arg0, %cst_2 : f32 loc(#loc14)
    %14 = tt.descriptor_load %arg4[%7, %c0_i32] : !tt.tensordesc<tensor<128x128xf16>> -> tensor<128x128xf16> loc(#loc15)
    %15 = arith.addi %7, %c128_i32 : i32 loc(#loc16)
    %16 = tt.descriptor_load %arg4[%15, %c0_i32] : !tt.tensordesc<tensor<128x128xf16>> -> tensor<128x128xf16> loc(#loc17)
    %17:7 = scf.for %arg25 = %c0_i32 to %arg24 step %c128_i32 iter_args(%arg26 = %cst, %arg27 = %cst_0, %arg28 = %cst_1, %arg29 = %cst, %arg30 = %cst_0, %arg31 = %cst_1, %arg32 = %5) -> (tensor<128xf32>, tensor<128xf32>, tensor<128x128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128x128xf32>, i32)  : i32 {
      %35 = tt.descriptor_load %arg9[%arg32, %c0_i32] : !tt.tensordesc<tensor<128x128xf16>> -> tensor<128x128xf16> loc(#loc75)
      %36 = tt.trans %35 {order = array<i32: 1, 0>} : tensor<128x128xf16> -> tensor<128x128xf16> loc(#loc76)
      %37 = tt.descriptor_load %arg14[%arg32, %c0_i32] : !tt.tensordesc<tensor<128x128xf16>> -> tensor<128x128xf16> loc(#loc77)
      %38 = tt.dot %14, %36, %cst_1, inputPrecision = tf32 : tensor<128x128xf16> * tensor<128x128xf16> -> tensor<128x128xf32> loc(#loc82)
      %39 = "tt.reduce"(%38) <{axis = 1 : i32}> ({
      ^bb0(%arg33: f32 loc(callsite(#loc1 at #loc83)), %arg34: f32 loc(callsite(#loc1 at #loc83))):
        %91 = arith.maxnumf %arg33, %arg34 : f32 loc(#loc138)
        tt.reduce.return %91 : f32 loc(#loc130)
      }) : (tensor<128x128xf32>) -> tensor<128xf32> loc(#loc130)
      %40 = tt.splat %13 : f32 -> tensor<128xf32> loc(#loc84)
      %41 = arith.mulf %39, %40 : tensor<128xf32> loc(#loc84)
      %42 = arith.maxnumf %arg27, %41 : tensor<128xf32> loc(#loc85)
      %43 = tt.splat %13 : f32 -> tensor<128x128xf32> loc(#loc86)
      %44 = arith.mulf %38, %43 : tensor<128x128xf32> loc(#loc86)
      %45 = tt.expand_dims %42 {axis = 1 : i32} : tensor<128xf32> -> tensor<128x1xf32> loc(#loc87)
      %46 = tt.broadcast %45 : tensor<128x1xf32> -> tensor<128x128xf32> loc(#loc88)
      %47 = arith.subf %44, %46 : tensor<128x128xf32> loc(#loc88)
      %48 = math.exp2 %47 : tensor<128x128xf32> loc(#loc89)
      %49 = arith.subf %arg27, %42 : tensor<128xf32> loc(#loc90)
      %50 = math.exp2 %49 : tensor<128xf32> loc(#loc91)
      %51 = "tt.reduce"(%48) <{axis = 1 : i32}> ({
      ^bb0(%arg33: f32 loc(callsite(#loc1 at #loc92)), %arg34: f32 loc(callsite(#loc1 at #loc92))):
        %91 = arith.addf %arg33, %arg34 : f32 loc(#loc139)
        tt.reduce.return %91 : f32 loc(#loc132)
      }) : (tensor<128x128xf32>) -> tensor<128xf32> loc(#loc132)
      %52 = tt.reshape %arg28 : tensor<128x128xf32> -> tensor<128x2x64xf32> loc(#loc93)
      %53 = tt.trans %52 {order = array<i32: 0, 2, 1>} : tensor<128x2x64xf32> -> tensor<128x64x2xf32> loc(#loc94)
      %outLHS, %outRHS = tt.split %53 : tensor<128x64x2xf32> -> tensor<128x64xf32> loc(#loc95)
      %54 = tt.expand_dims %50 {axis = 1 : i32} : tensor<128xf32> -> tensor<128x1xf32> loc(#loc96)
      %55 = tt.broadcast %54 : tensor<128x1xf32> -> tensor<128x64xf32> loc(#loc97)
      %56 = arith.mulf %outLHS, %55 : tensor<128x64xf32> loc(#loc97)
      %57 = arith.mulf %outRHS, %55 : tensor<128x64xf32> loc(#loc98)
      %58 = tt.join %56, %57 : tensor<128x64xf32> -> tensor<128x64x2xf32> loc(#loc99)
      %59 = tt.trans %58 {order = array<i32: 0, 2, 1>} : tensor<128x64x2xf32> -> tensor<128x2x64xf32> loc(#loc100)
      %60 = tt.reshape %59 : tensor<128x2x64xf32> -> tensor<128x128xf32> loc(#loc101)
      %61 = arith.truncf %48 : tensor<128x128xf32> to tensor<128x128xf16> loc(#loc102)
      %62 = tt.dot %61, %37, %60, inputPrecision = tf32 : tensor<128x128xf16> * tensor<128x128xf16> -> tensor<128x128xf32> loc(#loc103)
      %63 = arith.mulf %arg26, %50 : tensor<128xf32> loc(#loc104)
      %64 = arith.addf %63, %51 : tensor<128xf32> loc(#loc105)
      %65 = tt.dot %16, %36, %cst_1, inputPrecision = tf32 : tensor<128x128xf16> * tensor<128x128xf16> -> tensor<128x128xf32> loc(#loc106)
      %66 = "tt.reduce"(%65) <{axis = 1 : i32}> ({
      ^bb0(%arg33: f32 loc(callsite(#loc1 at #loc107)), %arg34: f32 loc(callsite(#loc1 at #loc107))):
        %91 = arith.maxnumf %arg33, %arg34 : f32 loc(#loc140)
        tt.reduce.return %91 : f32 loc(#loc134)
      }) : (tensor<128x128xf32>) -> tensor<128xf32> loc(#loc134)
      %67 = arith.mulf %66, %40 : tensor<128xf32> loc(#loc108)
      %68 = arith.maxnumf %arg30, %67 : tensor<128xf32> loc(#loc109)
      %69 = arith.mulf %65, %43 : tensor<128x128xf32> loc(#loc110)
      %70 = tt.expand_dims %68 {axis = 1 : i32} : tensor<128xf32> -> tensor<128x1xf32> loc(#loc111)
      %71 = tt.broadcast %70 : tensor<128x1xf32> -> tensor<128x128xf32> loc(#loc112)
      %72 = arith.subf %69, %71 : tensor<128x128xf32> loc(#loc112)
      %73 = math.exp2 %72 : tensor<128x128xf32> loc(#loc113)
      %74 = arith.subf %arg30, %68 : tensor<128xf32> loc(#loc114)
      %75 = math.exp2 %74 : tensor<128xf32> loc(#loc115)
      %76 = "tt.reduce"(%73) <{axis = 1 : i32}> ({
      ^bb0(%arg33: f32 loc(callsite(#loc1 at #loc116)), %arg34: f32 loc(callsite(#loc1 at #loc116))):
        %91 = arith.addf %arg33, %arg34 : f32 loc(#loc141)
        tt.reduce.return %91 : f32 loc(#loc136)
      }) : (tensor<128x128xf32>) -> tensor<128xf32> loc(#loc136)
      %77 = tt.reshape %arg31 : tensor<128x128xf32> -> tensor<128x2x64xf32> loc(#loc117)
      %78 = tt.trans %77 {order = array<i32: 0, 2, 1>} : tensor<128x2x64xf32> -> tensor<128x64x2xf32> loc(#loc118)
      %outLHS_3, %outRHS_4 = tt.split %78 : tensor<128x64x2xf32> -> tensor<128x64xf32> loc(#loc119)
      %79 = tt.expand_dims %75 {axis = 1 : i32} : tensor<128xf32> -> tensor<128x1xf32> loc(#loc120)
      %80 = tt.broadcast %79 : tensor<128x1xf32> -> tensor<128x64xf32> loc(#loc121)
      %81 = arith.mulf %outLHS_3, %80 : tensor<128x64xf32> loc(#loc121)
      %82 = arith.mulf %outRHS_4, %80 : tensor<128x64xf32> loc(#loc122)
      %83 = tt.join %81, %82 : tensor<128x64xf32> -> tensor<128x64x2xf32> loc(#loc123)
      %84 = tt.trans %83 {order = array<i32: 0, 2, 1>} : tensor<128x64x2xf32> -> tensor<128x2x64xf32> loc(#loc124)
      %85 = tt.reshape %84 : tensor<128x2x64xf32> -> tensor<128x128xf32> loc(#loc125)
      %86 = arith.truncf %73 : tensor<128x128xf32> to tensor<128x128xf16> loc(#loc126)
      %87 = tt.dot %86, %37, %85, inputPrecision = tf32 : tensor<128x128xf16> * tensor<128x128xf16> -> tensor<128x128xf32> loc(#loc127)
      %88 = arith.mulf %arg29, %75 : tensor<128xf32> loc(#loc128)
      %89 = arith.addf %88, %76 : tensor<128xf32> loc(#loc129)
      %90 = arith.addi %arg32, %c128_i32 : i32 loc(#loc80)
      scf.yield %64, %42, %62, %89, %68, %87, %90 : tensor<128xf32>, tensor<128xf32>, tensor<128x128xf32>, tensor<128xf32>, tensor<128xf32>, tensor<128x128xf32>, i32 loc(#loc81)
    } {tt.disallow_acc_multi_buffer, tt.divisibility_arg1 = dense<128> : tensor<1xi32>, tt.warp_specialize} loc(#loc74)
    %18 = math.log2 %17#0 : tensor<128xf32> loc(#loc55)
    %19 = arith.addf %17#1, %18 : tensor<128xf32> loc(#loc56)
    %20 = tt.expand_dims %17#0 {axis = 1 : i32} : tensor<128xf32> -> tensor<128x1xf32> loc(#loc57)
    %21 = tt.broadcast %20 : tensor<128x1xf32> -> tensor<128x128xf32> loc(#loc58)
    %22 = arith.divf %17#2, %21 : tensor<128x128xf32> loc(#loc58)
    %23 = arith.muli %1, %arg24 : i32 loc(#loc59)
    %24 = tt.addptr %arg1, %23 : !tt.ptr<f32>, i32 loc(#loc60)
    %25 = tt.splat %24 : !tt.ptr<f32> -> tensor<128x!tt.ptr<f32>> loc(#loc61)
    %26 = tt.addptr %25, %10 : tensor<128x!tt.ptr<f32>>, tensor<128xi32> loc(#loc61)
    tt.store %26, %19 : tensor<128x!tt.ptr<f32>> loc(#loc62)
    %27 = arith.truncf %22 : tensor<128x128xf32> to tensor<128x128xf16> loc(#loc63)
    tt.descriptor_store %arg19[%7, %c0_i32], %27 : !tt.tensordesc<tensor<128x128xf16>>, tensor<128x128xf16> loc(#loc64)
    %28 = math.log2 %17#3 : tensor<128xf32> loc(#loc65)
    %29 = arith.addf %17#4, %28 : tensor<128xf32> loc(#loc66)
    %30 = tt.expand_dims %17#3 {axis = 1 : i32} : tensor<128xf32> -> tensor<128x1xf32> loc(#loc67)
    %31 = tt.broadcast %30 : tensor<128x1xf32> -> tensor<128x128xf32> loc(#loc68)
    %32 = arith.divf %17#5, %31 : tensor<128x128xf32> loc(#loc68)
    %33 = tt.addptr %25, %12 : tensor<128x!tt.ptr<f32>>, tensor<128xi32> loc(#loc69)
    tt.store %33, %29 : tensor<128x!tt.ptr<f32>> loc(#loc70)
    %34 = arith.truncf %32 : tensor<128x128xf32> to tensor<128x128xf16> loc(#loc71)
    tt.descriptor_store %arg19[%15, %c0_i32], %34 : !tt.tensordesc<tensor<128x128xf16>>, tensor<128x128xf16> loc(#loc72)
    tt.return loc(#loc73)
  } loc(#loc)
} loc(#loc)
#loc2 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":452:28)
#loc3 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":453:27)
#loc4 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":454:22)
#loc5 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":455:21)
#loc6 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":457:31)
#loc7 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":457:23)
#loc8 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":458:39)
#loc9 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":458:29)
#loc10 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":460:47)
#loc11 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":460:34)
#loc12 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":461:56)
#loc13 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":461:34)
#loc14 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":473:16)
#loc15 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":475:21)
#loc16 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":476:36)
#loc17 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":476:21)
#loc18 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":203:78)
#loc20 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":206:24)
#loc21 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":206:12)
#loc22 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":207:24)
#loc23 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":148:19)
#loc25 = loc("/home/mren/OpenSource2/triton/python/triton/language/standard.py":188:40)
#loc27 = loc("/home/mren/OpenSource2/triton/python/triton/language/standard.py":167:27)
#loc28 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":155:47)
#loc29 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":155:31)
#loc30 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":156:18)
#loc31 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":156:34)
#loc32 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":156:29)
#loc33 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":157:21)
#loc34 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":159:31)
#loc35 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":159:25)
#loc36 = loc("/home/mren/OpenSource2/triton/python/triton/language/standard.py":290:36)
#loc38 = loc("/home/mren/OpenSource2/triton/python/triton/language/standard.py":260:15)
#loc39 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":166:29)
#loc40 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":166:59)
#loc41 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":166:17)
#loc42 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":167:24)
#loc43 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":167:18)
#loc44 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":168:18)
#loc45 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":169:24)
#loc46 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":169:44)
#loc47 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":169:55)
#loc48 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":172:13)
#loc49 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":174:23)
#loc50 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":177:16)
#loc51 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":177:24)
#loc53 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":212:22)
#loc54 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":212:8)
#loc55 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":493:25)
#loc56 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":493:12)
#loc57 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":494:23)
#loc58 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":494:18)
#loc59 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":495:27)
#loc60 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":495:18)
#loc61 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":495:35)
#loc62 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":496:22)
#loc63 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":497:43)
#loc64 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":497:35)
#loc65 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":499:25)
#loc66 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":499:12)
#loc67 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":500:23)
#loc68 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":500:18)
#loc69 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":501:35)
#loc70 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":502:22)
#loc71 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":503:54)
#loc72 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":503:46)
#loc73 = loc("/home/mren/OpenSource2/triton/python/tutorials/06-fused-attention.py":503:4)
#loc74 = loc(callsite(#loc18 at #loc19))
#loc75 = loc(callsite(#loc20 at #loc19))
#loc76 = loc(callsite(#loc21 at #loc19))
#loc77 = loc(callsite(#loc22 at #loc19))
#loc80 = loc(callsite(#loc53 at #loc19))
#loc81 = loc(callsite(#loc54 at #loc19))
#loc82 = loc(callsite(#loc23 at #loc78))
#loc84 = loc(callsite(#loc28 at #loc78))
#loc85 = loc(callsite(#loc29 at #loc78))
#loc86 = loc(callsite(#loc30 at #loc78))
#loc87 = loc(callsite(#loc31 at #loc78))
#loc88 = loc(callsite(#loc32 at #loc78))
#loc89 = loc(callsite(#loc33 at #loc78))
#loc90 = loc(callsite(#loc34 at #loc78))
#loc91 = loc(callsite(#loc35 at #loc78))
#loc93 = loc(callsite(#loc39 at #loc78))
#loc94 = loc(callsite(#loc40 at #loc78))
#loc95 = loc(callsite(#loc41 at #loc78))
#loc96 = loc(callsite(#loc42 at #loc78))
#loc97 = loc(callsite(#loc43 at #loc78))
#loc98 = loc(callsite(#loc44 at #loc78))
#loc99 = loc(callsite(#loc45 at #loc78))
#loc100 = loc(callsite(#loc46 at #loc78))
#loc101 = loc(callsite(#loc47 at #loc78))
#loc102 = loc(callsite(#loc48 at #loc78))
#loc103 = loc(callsite(#loc49 at #loc78))
#loc104 = loc(callsite(#loc50 at #loc78))
#loc105 = loc(callsite(#loc51 at #loc78))
#loc106 = loc(callsite(#loc23 at #loc79))
#loc108 = loc(callsite(#loc28 at #loc79))
#loc109 = loc(callsite(#loc29 at #loc79))
#loc110 = loc(callsite(#loc30 at #loc79))
#loc111 = loc(callsite(#loc31 at #loc79))
#loc112 = loc(callsite(#loc32 at #loc79))
#loc113 = loc(callsite(#loc33 at #loc79))
#loc114 = loc(callsite(#loc34 at #loc79))
#loc115 = loc(callsite(#loc35 at #loc79))
#loc117 = loc(callsite(#loc39 at #loc79))
#loc118 = loc(callsite(#loc40 at #loc79))
#loc119 = loc(callsite(#loc41 at #loc79))
#loc120 = loc(callsite(#loc42 at #loc79))
#loc121 = loc(callsite(#loc43 at #loc79))
#loc122 = loc(callsite(#loc44 at #loc79))
#loc123 = loc(callsite(#loc45 at #loc79))
#loc124 = loc(callsite(#loc46 at #loc79))
#loc125 = loc(callsite(#loc47 at #loc79))
#loc126 = loc(callsite(#loc48 at #loc79))
#loc127 = loc(callsite(#loc49 at #loc79))
#loc128 = loc(callsite(#loc50 at #loc79))
#loc129 = loc(callsite(#loc51 at #loc79))
#loc130 = loc(callsite(#loc25 at #loc83))
#loc132 = loc(callsite(#loc36 at #loc92))
#loc134 = loc(callsite(#loc25 at #loc107))
#loc136 = loc(callsite(#loc36 at #loc116))
#loc138 = loc(callsite(#loc27 at #loc130))
#loc139 = loc(callsite(#loc38 at #loc132))
#loc140 = loc(callsite(#loc27 at #loc134))
#loc141 = loc(callsite(#loc38 at #loc136))
